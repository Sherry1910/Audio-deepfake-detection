{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LCNN + FTANet Notebook for Audio Deepfake Detection (ASVspoof2019 LA)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 1: Setup ---\n", "!pip install librosa numpy torch torchaudio matplotlib tqdm scikit-learn\n", "\n", "import os\n", "import numpy as np\n", "import torch\n", "import torchaudio\n", "import librosa\n", "import matplotlib.pyplot as plt\n", "from torch import nn\n", "from torch.utils.data import Dataset, DataLoader\n", "from sklearn.metrics import roc_auc_score\n", "from tqdm import tqdm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 2: Dataset Loader ---\n", "class ASVspoofDataset(Dataset):\n", "    def __init__(self, file_list, labels, transform=None):\n", "        self.file_list = file_list\n", "        self.labels = labels\n", "        self.transform = transform\n", "\n", "    def __len__(self):\n", "        return len(self.file_list)\n", "\n", "    def __getitem__(self, idx):\n", "        file_path = self.file_list[idx]\n", "        waveform, sr = torchaudio.load(file_path)\n", "        mel = torchaudio.transforms.MelSpectrogram(sr)(waveform)\n", "        mel_db = torchaudio.transforms.AmplitudeToDB()(mel)\n", "        label = self.labels[idx]\n", "        return mel_db.squeeze(0), label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 3: Protocol File Parser ---\n", "def parse_protocol_file(protocol_path, audio_base_dir):\n", "    file_names = []\n", "    labels = []\n", "    with open(protocol_path, 'r') as f:\n", "        for line in f:\n", "            parts = line.strip().split()\n", "            filename = parts[1] + \".flac\"\n", "            label = 1 if parts[-1] == \"spoof\" else 0\n", "            file_names.append(os.path.join(audio_base_dir, filename))\n", "            labels.append(label)\n", "    return file_names, labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 4: LCNN Architecture ---\n", "class MFM(nn.Module):\n", "    def __init__(self, in_features, out_features, type=0):\n", "        super(MFM, self).__init__()\n", "        self.out_features = out_features\n", "        if type == 0:\n", "            self.filter = nn.Linear(in_features, out_features * 2)\n", "        else:\n", "            self.filter = nn.Conv2d(in_features, out_features * 2, kernel_size=3, padding=1)\n", "        self.type = type\n", "\n", "    def forward(self, x):\n", "        x = self.filter(x)\n", "        out = torch.split(x, self.out_features, 1)\n", "        return torch.max(out[0], out[1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LCNN(nn.Module):\n", "    def __init__(self, attention=False):\n", "        super(LCNN, self).__init__()\n", "        self.attention = attention\n", "\n", "        self.layer1 = nn.Sequential(\n", "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n", "            MFM(64, 32, type=1),\n", "            nn.MaxPool2d(2)\n", "        )\n", "        self.layer2 = nn.Sequential(\n", "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n", "            MFM(64, 32, type=1),\n", "            nn.MaxPool2d(2)\n", "        )\n", "\n", "        self.attn_time = nn.Sequential(\n", "            nn.Conv2d(32, 32, kernel_size=(1, 3), padding=(0, 1)),\n", "            nn.Sigmoid()\n", "        ) if attention else None\n", "\n", "        self.fc1 = nn.Linear(32 * 24 * 24, 256)\n", "        self.fc2 = nn.Linear(256, 1)\n", "\n", "    def forward(self, x):\n", "        x = x.unsqueeze(1)  # [B, 1, F, T]\n", "        x = self.layer1(x)\n", "        x = self.layer2(x)\n", "\n", "        if self.attention:\n", "            attn_mask = self.attn_time(x)\n", "            x = x * attn_mask\n", "\n", "        x = x.view(x.size(0), -1)\n", "        x = torch.relu(self.fc1(x))\n", "        x = torch.sigmoid(self.fc2(x)).squeeze(1)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 5: Training Loop ---\n", "def train(model, dataloader, optimizer, criterion, device):\n", "    model.train()\n", "    running_loss = 0\n", "    for X, y in tqdm(dataloader):\n", "        X, y = X.to(device), y.float().to(device)\n", "        optimizer.zero_grad()\n", "        outputs = model(X)\n", "        loss = criterion(outputs, y)\n", "        loss.backward()\n", "        optimizer.step()\n", "        running_loss += loss.item()\n", "    return running_loss / len(dataloader)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- Section 6: Evaluation ---\n", "def evaluate(model, dataloader, device):\n", "    model.eval()\n", "    all_preds, all_labels = [], []\n", "    with torch.no_grad():\n", "        for X, y in tqdm(dataloader):\n", "            X = X.to(device)\n", "            outputs = model(X).cpu().numpy()\n", "            all_preds.extend(outputs)\n", "            all_labels.extend(y.numpy())\n", "    auc = roc_auc_score(all_labels, all_preds)\n", "    return auc"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}